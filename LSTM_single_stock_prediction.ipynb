{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_single_stock_prediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MPrazzoli/AI_driven_investment_strategy/blob/main/LSTM_single_stock_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kro0V_GGnLNu",
        "outputId": "a6e1b57d-ffe5-4b5e-ee9b-fb110ac4970c"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCV9PZK6mAB4",
        "outputId": "2d5cecf6-ecb8-46be-c8ed-3b603311c158"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iZvDFPyms4w"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import csv\n",
        "from datetime import date, timedelta\n",
        "import tensorflow as tf\n",
        "\n",
        "# multivariate lstm example\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4KA9qiTms2X"
      },
      "source": [
        "class CorrelationClass(object):\n",
        "    # Initialization of the CorrelationClass object with the ticker symbol\n",
        "    def __init__(self, ticker):\n",
        "        self.principal_ticker = ticker\n",
        "        self.correlated_tickers_for_open_prediction = None # we compute the correlation between open and all other stock close/adjclose price\n",
        "        self.correlated_tickers_for_close_prediction = None # we compute the correlation between close/adjclose and all other stock open price"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BHiBejgmsz4"
      },
      "source": [
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "  X, y = list(), list()\n",
        "  for i in range(len(sequences)):\n",
        "    # find the end of this pattern\n",
        "    end_ix = i + n_steps\n",
        "    # check if we are beyond the dataset\n",
        "    if end_ix > len(sequences):\n",
        "        break\n",
        "    # gather input and output parts of the pattern\n",
        "    seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "    X.append(seq_x)\n",
        "    y.append(seq_y)\n",
        "  return array(X), array(y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuy06AQGmswk"
      },
      "source": [
        "open_df = pd.read_csv('/content/drive/MyDrive/_8_0_exported_dataframe/open', index_col='date')\n",
        "adjclose_df = pd.read_csv('/content/drive/MyDrive/_8_0_exported_dataframe/adjclose', index_col='date')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2ruDaZHmstx"
      },
      "source": [
        "ticker_list = open_df.columns"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XskPecUmsq5"
      },
      "source": [
        "correlation_object_dictionary = {'{0}'.format(ticker): CorrelationClass(ticker=ticker) for ticker in ticker_list}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXR0ovirrM-T"
      },
      "source": [
        "with open('/content/drive/MyDrive/_8_1_correlation_array/open_corr_prediction', 'r', newline='') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for i, row in enumerate(reader):\n",
        "      correlation_object_dictionary['{0}'.format(ticker_list[i])].correlated_tickers_for_open_prediction = row"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_J2ddb9rNgi"
      },
      "source": [
        "with open('/content/drive/MyDrive/_8_1_correlation_array/close_corr_prediction', 'r', newline='') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for i, row in enumerate(reader):\n",
        "      correlation_object_dictionary['{0}'.format(ticker_list[i])].correlated_tickers_for_close_prediction = row"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8DVyCu8rNd1"
      },
      "source": [
        "time = np.arange(len(open_df.index))\n",
        "time = np.delete(time, -1)\n",
        "\n",
        "# parameters\n",
        "split_time = round(len(open_df.index) * .80)\n",
        "# choose a number of time steps\n",
        "n_steps = 10 # numero di osservazioni da tenere in conto per una previsione... in questo caso 10 giorni\n",
        "# choose batch size\n",
        "batch_size = 32\n",
        "# choose shuffle buffer size\n",
        "shuffle_buffer_size = 500"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI0TaS2NrNa9"
      },
      "source": [
        "principal = 'ABC'\n",
        "\n",
        "# df_for_principal_and_indipendent = pd.concat([adjclose_df[correlation_object_dictionary['{0}'.format(principal)].correlated_tickers_for_open_prediction], stock_object_dictionary['{0}'.format(principal)].history['Open'].shift(-1)], axis=1)[:-1]\n",
        "dataset = pd.concat([adjclose_df[correlation_object_dictionary['{0}'.format(principal)].correlated_tickers_for_open_prediction[1:]], open_df[principal].shift(-1)], axis=1)[:-1].to_numpy()\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "# splitting between train and validation\n",
        "time_train = time[:split_time]\n",
        "x_train = X[:split_time]\n",
        "y_train = y[:split_time]\n",
        "time_valid = time[split_time:]\n",
        "x_valid = X[split_time:]\n",
        "y_valid = y[split_time:]\n",
        "\n",
        "# THE MODEL\n",
        "# the dataset knows the number of features, e.g. 2 or use the second dimension of X\n",
        "n_features = X.shape[2]\n",
        "\n",
        "# define model\n",
        "LSTMmodel = Sequential()\n",
        "LSTMmodel.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
        "LSTMmodel.add(Dense(1))\n",
        "LSTMmodel.compile(optimizer='adam', loss = tf.keras.losses.Huber(), metrics=[\"mae\"])\n",
        "# fit model\n",
        "history = LSTMmodel.fit(X, y, epochs=200, verbose=0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmOSPnGNr-Ex"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af6HsTyMr-4k"
      },
      "source": [
        "prediction trial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOhIpKpvr-BU",
        "outputId": "170fb32a-dd1e-470d-84cd-1f63ae6828ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "LSTMmodel.predict(X[0].reshape((1, n_steps, n_features)), verbose=0)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[98.72611]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXAuroJRrNYu"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}